# api.py

from fastapi import APIRouter, WebSocket, WebSocketDisconnect, UploadFile, File
from fastapi.responses import JSONResponse
from typing import List, Dict
import os, json, shutil, random, asyncio, cv2, numpy as np

router = APIRouter()

STATIC_DIR = "static"
UPLOADS_DIR = "uploads"
SIGN_DICT_PATH = os.path.join(STATIC_DIR, "data", "sign_dictionary.json")
TRANS_DICT_PATH = os.path.join(STATIC_DIR, "data", "translate_dictionary.json")

# Load dictionary
def load_sign_dictionary():
    try:
        with open(SIGN_DICT_PATH, encoding="utf-8") as f:
            return json.load(f)
    except FileNotFoundError:
        return []
    
def load_translation_dictionary():
    try:
        with open(TRANS_DICT_PATH, encoding="utf-8") as f:
            return json.load(f)
    except FileNotFoundError:
        return []

sign_dictionary = load_sign_dictionary()
translation_dictionary = load_translation_dictionary()


# ---------------------- 1. í•™ìŠµí•˜ê¸° ----------------------
@router.get("/learn")
def get_learning_words():
    """ëœë¤ ìëª¨ ë°˜í™˜ (ê°ê´€ì‹ ì œê³µìš©)"""
    
    # ì°¾ì„ word ëª©ë¡
    target_words = {"ã…‚", "ì–¼ë§ˆ", "ã…", "ì•„ë‹ˆìš”"}

    filtered = [item for item in sign_dictionary if item["word"] in target_words]
    return filtered


# 1-2. ---------------- ì‹¤ì‹œê°„ í˜•ì‹
@router.websocket("/stream/learn")
async def websocket_learn(websocket: WebSocket):
    """í•™ìŠµ ëª¨ë“œ: ì‹¤ì‹œê°„ ì˜ìƒ í”„ë ˆì„ ë°›ì•„ì„œ ì •í™•ë„ ê³„ì‚°"""
    await websocket.accept()
    frame_buffer = []
    SEQ_LENGTH = 10  # í”„ë ˆì„ ê°œìˆ˜ ê¸°ì¤€
    try:
        while True:
            frame = await websocket.receive_bytes()
            frame_buffer.append(frame)

            if len(frame_buffer) == SEQ_LENGTH:
                # 10ê°œ í”„ë ˆì„ ëª¨ì˜€ì„ ë•Œ AI ë¶„ì„
                # TODO: ì‹¤ì œ AI ë¶„ì„ í•¨ìˆ˜ë¡œ ì²˜ë¦¬
                #processed_result = process_frame_batch(frame_buffer)
                frame_buffer = []  # ë²„í¼ ë¹„ìš°ê¸°

                # ì„ì‹œ ì •í™•ë„ ë° ì œìŠ¤ì²˜ íŒë‹¨ (ì˜ˆì‹œ)
                result = {
                    "gesture": "ã„±",  # ì‹¤ì œ ëª¨ë¸ ê²°ê³¼
                    "confidence": round(random.uniform(0.85, 0.98), 3)
                }

                await websocket.send_text(json.dumps(result))
    except WebSocketDisconnect:
        print("ì›¹ì†Œì¼“ ì—°ê²° ì¢…ë£Œ (í•™ìŠµ)")


# ---------------------- 2. í•™ìŠµ í…ŒìŠ¤íŠ¸í•˜ê¸° ----------------------

@router.get("/test/random")
def get_random_test_word():
    """ëœë¤ ìëª¨ ë°˜í™˜ (ê°ê´€ì‹ ì œê³µìš©)"""
    random_word = random.choice(sign_dictionary)
    return {"id": random_word["id"], "word": random_word["word"], "video_url": random_word["video_url"]}

@router.post("/test/submit")
def check_test_answer(word_id: int, selected: str):
    """ì •ë‹µ ì²´í¬"""
    word = next((w for w in sign_dictionary if w["id"] == word_id), None)
    if not word:
        return JSONResponse(status_code=404, content={"detail": "ë‹¨ì–´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."})
    is_correct = word["word"] == selected
    return {"correct": is_correct, "answer": word["word"]}


# ---------------- 3. ë²ˆì—­
@router.get("/translate/{char}")
def get_translated_result(char: str):
    """ëˆ„ì  ìëª¨ â†’ ë‹¨ì–´ ë°˜í™˜ ë° ì™¸ë¶€ API ë²ˆì—­ ê²°ê³¼ ì „ë‹¬"""
    item = next((item for item in translation_dictionary if item["word"] == char), None)
    return item


# ---------------------- 4. ì›¹ì†Œì¼“ (ì‹¤ì‹œê°„ ì˜ìƒ ì²˜ë¦¬) ----------------------

receive_clients = set()
send_clients = set()

def draw_heart(img, center, size=50, color=(0, 0, 255), thickness=-1):
    x, y = center
    radius = size // 3
    cv2.circle(img, (x - radius, y - radius), radius, color, thickness)
    cv2.circle(img, (x + radius, y - radius), radius, color, thickness)
    pts = np.array([
        [x - size, y - radius],
        [x + size, y - radius],
        [x, y + size]
    ])
    cv2.fillPoly(img, [pts], color)

def process_frame(frame_bytes: bytes) -> bytes:
    # ë°”ì´íŠ¸ â†’ OpenCV ì´ë¯¸ì§€
    np_arr = np.frombuffer(frame_bytes, np.uint8)
    img = cv2.imdecode(np_arr, cv2.IMREAD_COLOR)

    # ì˜ˆ: í•˜íŠ¸ í‘œì‹œ
    draw_heart(img, center=(img.shape[1] // 2, img.shape[0] // 2))

    # ë‹¤ì‹œ OpenCV ì´ë¯¸ì§€ â†’ ë°”ì´íŠ¸ (JPEG ì¸ì½”ë”©)
    _, buffer = cv2.imencode('.jpg', img)
    return buffer.tobytes()
    
    # # ë°›ì€ í”„ë ˆì„ì„ ì²˜ë¦¬í•˜ëŠ” ë¡œì§ -> AI êµ¬í˜„

    # return frame_bytes  # ê°€ê³µ ì—†ì´ ê·¸ëŒ€ë¡œ ë°˜í™˜

@router.websocket("/stream/receive")
async def websocket_receive(websocket: WebSocket):
    await websocket.accept()
    receive_clients.add(websocket)
    try:
        while True:
            frame = await websocket.receive_bytes()
            print("ğŸ“¸ Frame received")  # ë¡œê·¸ ì¶”ê°€

            processed_frame = process_frame(frame)  # ì²˜ë¦¬ëœ í”„ë ˆì„

            # ëª¨ë“  send í´ë¼ì´ì–¸íŠ¸ì— ì²˜ë¦¬ëœ í”„ë ˆì„ ì „ì†¡
            disconnected = []
            for client in send_clients:
                try:
                    await client.send_bytes(processed_frame)
                except Exception:
                    disconnected.append(client)
            for dc in disconnected:
                send_clients.remove(dc)
    except WebSocketDisconnect:
        receive_clients.remove(websocket)


@router.websocket("/stream/send")
async def websocket_send(websocket: WebSocket):
    await websocket.accept()
    send_clients.add(websocket)
    try:
        while True:
            # ì†¡ì‹  í´ë¼ì´ì–¸íŠ¸ê°€ ì—°ê²° ìœ ì§€ìš©ìœ¼ë¡œ í…ìŠ¤íŠ¸ ë©”ì‹œì§€ ë³´ë‚´ì£¼ê±°ë‚˜
            # ê·¸ëƒ¥ ì—°ê²° ìœ ì§€ë§Œ í•  ìˆ˜ë„ ìˆìŒ
            await asyncio.sleep(10)
    except WebSocketDisconnect:
        send_clients.remove(websocket)


@router.websocket("/stream/predict")
async def websocket_predict(websocket: WebSocket):
    await websocket.accept()

    from tensorflow.keras.models import Sequential
    from tensorflow.keras.layers import LSTM, Dense
    import mediapipe as mp
    import numpy as np

    # ëª¨ë¸ ì´ˆê¸°í™”
    actions = np.array(['None', 'ê³„ì‚°', 'ê³ ë§™ë‹¤', 'ê´œì°®ë‹¤', 'ê¸°ë‹¤ë¦¬ë‹¤', 'ë‚˜', 'ë„¤', 'ë‹¤ìŒ',
                    'ë‹¬ë‹¤', 'ë”', 'ë„ì°©', 'ëˆ', 'ë˜', 'ë§µë‹¤', 'ë¨¼ì €', 'ë¬´ì—‡', 'ë¬¼', 'ë¬¼ìŒ',
                    'ë¶€íƒ', 'ì‚¬ëŒ', 'ìˆ˜ì €', 'ì‹œê°„', 'ì•„ë‹ˆìš”', 'ì–´ë””', 'ì–¼ë§ˆ', 'ì˜ˆì•½', 'ì˜¤ë‹¤',
                    'ìš°ë¦¬', 'ìŒì‹', 'ì´ê±°', 'ì¸ê¸°', 'ìˆë‹¤', 'ìë¦¬', 'ì ‘ì‹œ', 'ì œì¼', 'ì¡°ê¸ˆ',
                    'ì£¼ë¬¸', 'ì£¼ì„¸ìš”', 'ì§œë‹¤', 'ì±…', 'ì¶”ì²œ', 'í™”ì¥ì‹¤', 'í™•ì¸'])

    model = Sequential()
    model.add(LSTM(64, return_sequences=True, activation='relu', input_shape=(30, 126)))
    model.add(LSTM(128, return_sequences=True, activation='relu'))
    model.add(LSTM(64, return_sequences=False, activation='relu'))
    model.add(Dense(64, activation='relu'))
    model.add(Dense(32, activation='relu'))
    model.add(Dense(actions.shape[0], activation='softmax'))
    model.load_weights('./ai/word_model.h5')

    mp_holistic = mp.solutions.holistic
    holistic = mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5)

    sequence = []
    threshold = 0.75

    def extract_keypoints(results):
        lh = np.array([[res.x*3, res.y*3, res.z*3] for res in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(21*3)
        rh = np.array([[res.x*3, res.y*3, res.z*3] for res in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(21*3)
        return np.concatenate([lh, rh])

    try:
        while True:
            frame_bytes = await websocket.receive_bytes()

            # ë°”ì´íŠ¸ â†’ ì´ë¯¸ì§€
            np_arr = np.frombuffer(frame_bytes, np.uint8)
            image = cv2.imdecode(np_arr, cv2.IMREAD_COLOR)

            # Mediapipe ì²˜ë¦¬
            image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            results = holistic.process(image_rgb)
            keypoints = extract_keypoints(results)
            sequence.append(keypoints)
            if len(sequence) > 30:
                sequence.pop(0)

            if len(sequence) == 30:
                input_seq = np.expand_dims(sequence, axis=0)
                res = model.predict(input_seq)[0]
                predicted_word = ""
                if res[np.argmax(res)] > threshold:
                    predicted_word = actions[np.argmax(res)]
                await websocket.send_text(json.dumps({
                    "word": predicted_word,
                    "confidence": round(float(np.max(res)), 3)
                }))
    except WebSocketDisconnect:
        print("ì›¹ì†Œì¼“ ì—°ê²° ì¢…ë£Œ (predict)")
    finally:
        holistic.close()


import tensorflow as tf
import platform
from ai.modules.utils import Vector_Normalization
import ai.modules.holistic_module as hm


@router.websocket("/stream/jamo")
async def websocket_jamo_predict(websocket: WebSocket):
    """ìëª¨ ì‹¤ì‹œê°„ ì¸ì‹ WebSocket"""
    await websocket.accept()

    # í™˜ê²½ ë° ëª¨ë¸ ì´ˆê¸°í™”
    actions = ['ã„±', 'ã„´', 'ã„·', 'ã„¹', 'ã…', 'ã…‚', 'ã……', 'ã…‡', 'ã…ˆ', 'ã…Š', 'ã…‹', 'ã…Œ', 'ã…', 'ã…',
               'ã…', 'ã…‘', 'ã…“', 'ã…•', 'ã…—', 'ã…›', 'ã…œ', 'ã… ', 'ã…¡', 'ã…£',
               'ã…', 'ã…’', 'ã…”', 'ã…–', 'ã…¢', 'ã…š', 'ã…Ÿ']
    seq_length = 10
    seq = []
    action_seq = []
    last_action = None

    # TFLite ëª¨ë¸ ë¡œë”©
    interpreter = tf.lite.Interpreter(model_path="./ai/jamo_model.tflite")
    interpreter.allocate_tensors()
    input_details = interpreter.get_input_details()
    output_details = interpreter.get_output_details()

    # Mediapipe
    detector = hm.HolisticDetector(min_detection_confidence=0.3)

    try:
        while True:
            frame_bytes = await websocket.receive_bytes()
            np_arr = np.frombuffer(frame_bytes, np.uint8)
            img = cv2.imdecode(np_arr, cv2.IMREAD_COLOR)

            img = detector.findHolistic(img, draw=False)
            _, right_hand_lmList = detector.findRighthandLandmark(img)

            if right_hand_lmList is not None:
                joint = np.array([[lm.x, lm.y] for lm in right_hand_lmList.landmark])
                vector, angle_label = Vector_Normalization(joint)
                d = np.concatenate([vector.flatten(), angle_label.flatten()])
                seq.append(d)

                if len(seq) < seq_length:
                    continue

                input_data = np.expand_dims(np.array(seq[-seq_length:], dtype=np.float32), axis=0)
                interpreter.set_tensor(input_details[0]['index'], input_data)
                interpreter.invoke()

                y_pred = interpreter.get_tensor(output_details[0]['index'])
                i_pred = int(np.argmax(y_pred[0]))
                conf = y_pred[0][i_pred]

                if conf < 0.9:
                    continue

                action = actions[i_pred]
                action_seq.append(action)

                if len(action_seq) < 3:
                    continue

                this_action = "?"
                if action_seq[-1] == action_seq[-2] == action_seq[-3]:
                    this_action = action
                    if last_action != this_action:
                        last_action = this_action

                await websocket.send_text(json.dumps({
                    "word": this_action,
                    "confidence": round(float(conf), 3)
                }))
    except WebSocketDisconnect:
        print("ì›¹ì†Œì¼“ ì—°ê²° ì¢…ë£Œ (jamo)")
